{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:30:46.555009Z",
     "start_time": "2025-10-17T14:30:45.872583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Read from documents\n",
    "import requests\n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\"\"\"\n",
    "# You are repurposing the documents_raw file\n",
    "\"course\": \"data-engineering-zoomcamp\",\n",
    "    \"documents\": [\n",
    "      {\n",
    "        \"text\": \"The purpose of this document is to capture frequently asked technical....\"\n",
    "      },\n",
    "      ]\n",
    "\n",
    "# to an documents array with the course name in it\n",
    "\n",
    "\"\"\"\n",
    "documents = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for record in documents_raw:\n",
    "    course_name = record['course'] # record is course and documents. We are pulling out the course name.\n",
    "    for element in record['documents']: # element is \"text\": \"The purpose of this document is to capture frequently asked technical....\"\n",
    "        element['course'] = course_name\n",
    "        documents.append(element)\n"
   ],
   "id": "11d6db7244d5e3b7",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-17T14:33:03.206337Z",
     "start_time": "2025-10-17T14:32:51.712706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Vector Search is based on cosine similarity, and we need to convert the text to vectors (number representations. We need an embedding model for that)\n",
    "# Other models can be found here https://sbert.net/docs/sentence_transformer/pretrained_models.html#multi-qa-models\n",
    "# https://huggingface.co/sentence-transformers/multi-qa-distilbert-dot-v1\n",
    "# https://youtu.be/wjZofJX0v4M?si=n63ejz0XTVwufdwP&t=1005\n",
    "# note : qa stands for question-answer,\n",
    "# dot stand for dot product\n",
    "# cos stands for cosine similarity\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer('multi-qa-distilbert-cos-v1')"
   ],
   "id": "1ee908f05bf7772f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T16:33:27.326957Z",
     "start_time": "2025-10-17T16:33:27.248857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Understand Vectors\n",
    "docs = [\n",
    "    [\"I just discovered the course, can I still join?\"], #Q1 (Question 1)\n",
    "    [\"I just found out about this program, Can I still enroll\"], #Q2 (Question 2)\n",
    "    [\"You can join the course at any point of time\"] # D (Description)\n",
    "]\n",
    "\n",
    "vectors_example = []\n",
    "\n",
    "for d in docs:\n",
    "    v = embedding_model.encode(d)\n",
    "    vectors_example.append(v)\n",
    "\n",
    "#We now have  Question1, Question2 and Description in a vector representation.\n",
    "# We find similarity between questions and then questions with the description\n",
    "\n",
    "# Dot Products :\n",
    "# Values is positive if vector point in same directions (i.e they are similar)\n",
    "#  Value moves to zero when its perpendicular (no similarity)\n",
    "# Value moves to negative when it's more than 90 ( opposite)\n",
    "# https://youtu.be/wjZofJX0v4M?si=n63ejz0XTVwufdwP&t=1005\n",
    "\n",
    "q1, q2, d = vectors_example\n",
    "\n",
    "\n",
    "print(f\"Q1 shape : {q1.shape}\") # (1,768)\n",
    "print(f\"Q2 shape : {q2.shape}\") # (1,768)\n",
    "\n",
    "#When doing dot multiplication we need to transpose i.e 1,768 cannot dot product with 1,768 , it can only multiply with 7\n",
    "\n",
    "print(f\"Q1 shape : {q1.shape}\") # (1,768)\n",
    "print(f\"Q2 Transpose shape : {q2.T.shape}\") # (768, 1)\n",
    "\n",
    "print(f\"Q1 dot d : {q1.dot(d.T)}\") # 0.7205941(Closer to 1 and positive, good similarity between Q1 and Q2)\n",
    "\n",
    "print(f\"Q2 dot d : {q2.dot(d.T)}\") # 0.48303062 (Closer to 1 and positive, ok similarity between Q1 and D but better than text match which would have returned 0)\n",
    "\n",
    "print(f\"Q1 dot Q2 : {q1.dot(q2.T)}\") # 0.606797 (Closer to 1 and positive, good similarity between Q1 and Q2). So given a Q2 and we do a cosine vector search, we will find Q2\n"
   ],
   "id": "a8190d7983149733",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 shape : (1, 768)\n",
      "Q2 shape : (1, 768)\n",
      "Q1 shape : (1, 768)\n",
      "Q2 Transpose shape : (768, 1)\n",
      "Q1 dot d : [[0.7205941]]\n",
      "Q2 dot d : [[0.48303062]]\n",
      "Q1 dot Q2 : [[0.6067974]]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T15:32:03.120134Z",
     "start_time": "2025-10-17T15:31:50.884060Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d2f995a81df4706a9a0e7bc5d1fc080"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3,
   "source": [
    "#Use the embedding model to create an array of vectors.\n",
    "#for that we combine the question: and text: part of the documents sections\n",
    "# This is what worked, wouldn't necessarily work for all\n",
    "# idea is given a q2 and we have the q1 and answer in the same \"string\" we can find the similar text and send it to LLM.\n",
    "\"\"\"\n",
    "[\n",
    "      {\n",
    "        \"text\": \"The purpose of this document is to capture frequently asked technical ...\",\n",
    "        \"section\": \"General course-related questions\",\n",
    "        \"question\": \"Course - When will the course start?\"\n",
    "      },\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for d in tqdm(documents):\n",
    "    text = d['question'] + ' ' + d['text']\n",
    "    v = embedding_model.encode(text)\n",
    "    embeddings.append(v)\n",
    "\n",
    "embeddings = np.array(embeddings)"
   ],
   "id": "2267329388227507"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T16:48:33.063641Z",
     "start_time": "2025-10-17T16:48:33.058820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from minsearch import VectorSearch\n",
    "\n",
    "vector_index = VectorSearch(keyword_fields=['course'])\n",
    "vector_index.fit(embeddings, documents)\n",
    "\n",
    "# Create a vector Search functon\n",
    "\n",
    "def vector_compare_search(question):\n",
    "    q = embedding_model.encode(question)\n",
    "\n",
    "    return vector_index.search(\n",
    "        q,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        num_results=5\n",
    "    )"
   ],
   "id": "16394ed9407e3994",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T16:48:35.027060Z",
     "start_time": "2025-10-17T16:48:34.976272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from minsearch import Index\n",
    "\n",
    "search_index = Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "search_index.fit(documents)\n",
    "\n",
    "# Create a Simple compare text function functon\n",
    "def text_compare_search(question):\n",
    "    q = embedding_model.encode(question)\n",
    "    return search_index.search(\n",
    "        q,\n",
    "    )\n"
   ],
   "id": "c27e79d729cb40a1",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T16:48:53.058347Z",
     "start_time": "2025-10-17T16:48:53.055797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build your system prompt\n",
    "import json\n",
    "\n",
    "instructions = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(question, search_results):\n",
    "    search_json = json.dumps(search_results)\n",
    "    return prompt_template.format(\n",
    "        question=question,\n",
    "        context=search_json\n",
    "    )"
   ],
   "id": "681725287e989773",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T16:49:45.140494Z",
     "start_time": "2025-10-17T16:49:45.116930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Interact with LLM\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "def interact_with_llm(user_prompt, instructions=None, model=\"gpt-4o-mini\"):\n",
    "    messages = []\n",
    "\n",
    "    if instructions:\n",
    "        messages.append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": instructions\n",
    "        })\n",
    "\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_prompt\n",
    "    })\n",
    "\n",
    "    response = openai_client.responses.create(\n",
    "        model=model,\n",
    "        input=messages\n",
    "    )\n",
    "\n",
    "    return response.output_text"
   ],
   "id": "604ce18dafe0dac4",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T16:49:52.174200Z",
     "start_time": "2025-10-17T16:49:49.727375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get output with Vector Search\n",
    "def vector_search_rag(question):\n",
    "    search_results = vector_compare_search(question)\n",
    "    user_prompt = build_prompt(question, search_results)\n",
    "    return interact_with_llm(user_prompt, instructions=instructions)\n",
    "\n",
    "vector_search_rag('what is the name of your program')\n"
   ],
   "id": "e989668b42191de7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The name of the program is \"Data Engineering Zoom Camp 2024.\"'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T16:50:15.354940Z",
     "start_time": "2025-10-17T16:50:15.179824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Get output with Text Search (TODO:needs to be fixed)\n",
    "def hybrid_search_rag(question):\n",
    "    vector_search_results = vector_compare_search(question)\n",
    "    text_search_results = text_compare_search(question)\n",
    "    user_prompt = build_prompt(question, vector_search_results + text_search_results)\n",
    "    return interact_with_llm(user_prompt, instructions=instructions)\n",
    "\n",
    "hybrid_search_rag('what is the name of your program')"
   ],
   "id": "ee72d9f39f17a346",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[39]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      5\u001B[39m     user_prompt = build_prompt(question, vector_search_results + text_search_results)\n\u001B[32m      6\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m interact_with_llm(user_prompt, instructions=instructions)\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m \u001B[43mhybrid_search_rag\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mwhat is the name of your program\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[39]\u001B[39m\u001B[32m, line 4\u001B[39m, in \u001B[36mhybrid_search_rag\u001B[39m\u001B[34m(question)\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mhybrid_search_rag\u001B[39m(question):\n\u001B[32m      3\u001B[39m     vector_search_results = vector_compare_search(question)\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m     text_search_results = \u001B[43mtext_compare_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      5\u001B[39m     user_prompt = build_prompt(question, vector_search_results + text_search_results)\n\u001B[32m      6\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m interact_with_llm(user_prompt, instructions=instructions)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[29]\u001B[39m\u001B[32m, line 13\u001B[39m, in \u001B[36mtext_compare_search\u001B[39m\u001B[34m(question)\u001B[39m\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mtext_compare_search\u001B[39m(question):\n\u001B[32m     12\u001B[39m     q = embedding_model.encode(question)\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msearch_index\u001B[49m\u001B[43m.\u001B[49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m        \u001B[49m\u001B[43mq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Agents/ai-bootcamp-rag-to-agents/.venv/lib/python3.12/site-packages/minsearch/minsearch.py:109\u001B[39m, in \u001B[36mIndex.search\u001B[39m\u001B[34m(self, query, filter_dict, boost_dict, num_results, output_ids)\u001B[39m\n\u001B[32m    106\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.docs:\n\u001B[32m    107\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m []\n\u001B[32m--> \u001B[39m\u001B[32m109\u001B[39m query_vecs = {field: \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mvectorizers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mfield\u001B[49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m field \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.text_fields}\n\u001B[32m    110\u001B[39m scores = np.zeros(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m.docs))\n\u001B[32m    112\u001B[39m \u001B[38;5;66;03m# Compute cosine similarity for each text field and apply boost\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Agents/ai-bootcamp-rag-to-agents/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:2129\u001B[39m, in \u001B[36mTfidfVectorizer.transform\u001B[39m\u001B[34m(self, raw_documents)\u001B[39m\n\u001B[32m   2112\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Transform documents to document-term matrix.\u001B[39;00m\n\u001B[32m   2113\u001B[39m \n\u001B[32m   2114\u001B[39m \u001B[33;03mUses the vocabulary and document frequencies (df) learned by fit (or\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   2125\u001B[39m \u001B[33;03m    Tf-idf-weighted document-term matrix.\u001B[39;00m\n\u001B[32m   2126\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   2127\u001B[39m check_is_fitted(\u001B[38;5;28mself\u001B[39m, msg=\u001B[33m\"\u001B[39m\u001B[33mThe TF-IDF vectorizer is not fitted\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m2129\u001B[39m X = \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_documents\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2130\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._tfidf.transform(X, copy=\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Agents/ai-bootcamp-rag-to-agents/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1422\u001B[39m, in \u001B[36mCountVectorizer.transform\u001B[39m\u001B[34m(self, raw_documents)\u001B[39m\n\u001B[32m   1419\u001B[39m \u001B[38;5;28mself\u001B[39m._check_vocabulary()\n\u001B[32m   1421\u001B[39m \u001B[38;5;66;03m# use the same matrix-building strategy as fit_transform\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1422\u001B[39m _, X = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_count_vocab\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_documents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfixed_vocab\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m   1423\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.binary:\n\u001B[32m   1424\u001B[39m     X.data.fill(\u001B[32m1\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Agents/ai-bootcamp-rag-to-agents/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1264\u001B[39m, in \u001B[36mCountVectorizer._count_vocab\u001B[39m\u001B[34m(self, raw_documents, fixed_vocab)\u001B[39m\n\u001B[32m   1262\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m raw_documents:\n\u001B[32m   1263\u001B[39m     feature_counter = {}\n\u001B[32m-> \u001B[39m\u001B[32m1264\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m feature \u001B[38;5;129;01min\u001B[39;00m \u001B[43manalyze\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[32m   1265\u001B[39m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1266\u001B[39m             feature_idx = vocabulary[feature]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Agents/ai-bootcamp-rag-to-agents/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:104\u001B[39m, in \u001B[36m_analyze\u001B[39m\u001B[34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001B[39m\n\u001B[32m    102\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    103\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m preprocessor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m104\u001B[39m         doc = \u001B[43mpreprocessor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    105\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m tokenizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    106\u001B[39m         doc = tokenizer(doc)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Agents/ai-bootcamp-rag-to-agents/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:62\u001B[39m, in \u001B[36m_preprocess\u001B[39m\u001B[34m(doc, accent_function, lower)\u001B[39m\n\u001B[32m     43\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Chain together an optional series of text preprocessing steps to\u001B[39;00m\n\u001B[32m     44\u001B[39m \u001B[33;03mapply to a document.\u001B[39;00m\n\u001B[32m     45\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m     59\u001B[39m \u001B[33;03m    preprocessed string\u001B[39;00m\n\u001B[32m     60\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     61\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m lower:\n\u001B[32m---> \u001B[39m\u001B[32m62\u001B[39m     doc = \u001B[43mdoc\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlower\u001B[49m()\n\u001B[32m     63\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m accent_function \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     64\u001B[39m     doc = accent_function(doc)\n",
      "\u001B[31mAttributeError\u001B[39m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
