{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-26T01:14:43.353370Z",
     "start_time": "2025-10-26T01:14:42.636987Z"
    }
   },
   "source": [
    "# Get Data from documents\n",
    "\n",
    "import requests\n",
    "from openai.types.responses import ResponseFunctionToolCall\n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "\n",
    "documents = []\n",
    "\n",
    "for record in documents_raw:\n",
    "    course_name = record['course'] #data-engineering-zoomcamp#\n",
    "\n",
    "    for element in record['documents']: #documents[]\n",
    "        element['course'] = course_name\n",
    "        documents.append(element)"
   ],
   "outputs": [],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T01:14:43.423928Z",
     "start_time": "2025-10-26T01:14:43.358990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create an Appendable Index ( Advantage is that we can keep adding to an appendable index)\n",
    "from minsearch import AppendableIndex\n",
    "\n",
    "\n",
    "# text fields are tokenized and put in an inverted index.\n",
    "# Overview of how the index workds below\n",
    "\"\"\"\n",
    "üß©Text Fields and  Inverted Index ‚Äî Complete Side-by-Side Diagram\n",
    "(for text_fields=[\"question\", \"text\", \"section\"])\n",
    "\n",
    "Example Documents:\n",
    "\n",
    "Doc 0:\n",
    "    question: \"What is deep learning?\"\n",
    "    text:     \"Deep learning is a subset of machine learning.\"\n",
    "    section:  \"AI Basics\"\n",
    "\n",
    "Doc 1:\n",
    "    question: \"How to use Python?\"\n",
    "    text:     \"Python is widely used for data analysis.\"\n",
    "    section:  \"Programming\"\n",
    "\n",
    "Doc 2:\n",
    "    question: \"What is machine learning?\"\n",
    "    text:     \"Machine learning involves algorithms that learn from data.\"\n",
    "    section:  \"AI Basics\"\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "Tokenization (stop words removed, lowercase)\n",
    "\n",
    "Doc 0 tokens:\n",
    "    question ‚Üí [\"deep\", \"learning\"]\n",
    "    text     ‚Üí [\"deep\", \"learning\", \"subset\", \"machine\", \"learning\"]\n",
    "    section  ‚Üí [\"ai\", \"basics\"]\n",
    "\n",
    "Doc 1 tokens:\n",
    "    question ‚Üí [\"python\", \"use\"]\n",
    "    text     ‚Üí [\"python\", \"widely\", \"used\", \"data\", \"analysis\"]\n",
    "    section  ‚Üí [\"programming\"]\n",
    "\n",
    "Doc 2 tokens:\n",
    "    question ‚Üí [\"machine\", \"learning\"]\n",
    "    text     ‚Üí [\"machine\", \"learning\", \"involves\", \"algorithms\", \"learn\", \"data\"]\n",
    "    section  ‚Üí [\"ai\", \"basics\"]\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "Inverted Index ‚Äî Side-by-Side View\n",
    "\n",
    "+----------------+---------------------------+------------------+\n",
    "| question field | text field                | section field    |\n",
    "+----------------+---------------------------+------------------+\n",
    "| deep     ‚Üí [0] | deep       ‚Üí [0]          | ai          ‚Üí [0,2] |\n",
    "| learning ‚Üí [0,2]| learning   ‚Üí [0,2]       | basics      ‚Üí [0,2] |\n",
    "| python   ‚Üí [1] | subset     ‚Üí [0]          | programming ‚Üí [1]   |\n",
    "| use      ‚Üí [1] | machine    ‚Üí [0,2]        |                  |\n",
    "| machine  ‚Üí [2] | python     ‚Üí [1]          |                  |\n",
    "|                | widely     ‚Üí [1]          |                  |\n",
    "|                | used       ‚Üí [1]          |                  |\n",
    "|                | data       ‚Üí [1,2]        |                  |\n",
    "|                | analysis   ‚Üí [1]          |                  |\n",
    "|                | involves   ‚Üí [2]          |                  |\n",
    "|                | algorithms ‚Üí [2]          |                  |\n",
    "|                | learn      ‚Üí [2]          |                  |\n",
    "+----------------+---------------------------+------------------+\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "Example Search:\n",
    "\n",
    "Query: \"deep learning in AI\" ‚Üí [\"deep\", \"learning\", \"ai\"]\n",
    "\n",
    "Lookup in inverted index:\n",
    "\n",
    "question field:\n",
    "    \"deep\" ‚Üí [0]\n",
    "    \"learning\" ‚Üí [0,2]\n",
    "    \"ai\" ‚Üí []\n",
    "\n",
    "text field:\n",
    "    \"deep\" ‚Üí [0]\n",
    "    \"learning\" ‚Üí [0,2]\n",
    "    \"ai\" ‚Üí []\n",
    "\n",
    "section field:\n",
    "    \"deep\" ‚Üí []\n",
    "    \"learning\" ‚Üí []\n",
    "    \"ai\" ‚Üí [0,2]\n",
    "\n",
    "Candidate documents = union of all matches ‚Üí [0,2]\n",
    "\n",
    "Rank using TF-IDF across fields.\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "Summary:\n",
    "\n",
    "This diagram shows:\n",
    "\n",
    "1. Original documents\n",
    "2. Tokens extracted per text field\n",
    "3. Inverted index mapping tokens ‚Üí document IDs\n",
    "\n",
    "It demonstrates how `AppendableIndex` efficiently finds candidate documents\n",
    "without scanning all documents.\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "üß© Keyword Fields ‚Äî Side-by-Side Diagram\n",
    "(for keyword_fields=[\"category\", \"author\", \"year\"])\n",
    "\n",
    "Example Documents:\n",
    "\n",
    "Doc 0:\n",
    "    category: \"AI\"\n",
    "    author:   \"Andrew Ng\"\n",
    "    year:     2023\n",
    "\n",
    "Doc 1:\n",
    "    category: \"Programming\"\n",
    "    author:   \"Guido van Rossum\"\n",
    "    year:     2022\n",
    "\n",
    "Doc 2:\n",
    "    category: \"AI\"\n",
    "    author:   \"Geoff Hinton\"\n",
    "    year:     2023\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "Keyword Field Mapping (Value ‚Üí Document IDs)\n",
    "\n",
    "+--------------+---------------------+------------+\n",
    "| category     | author              | year       |\n",
    "+--------------+---------------------+------------+\n",
    "| AI           ‚Üí [0,2]   | Andrew Ng        ‚Üí [0] | 2023 ‚Üí [0,2] |\n",
    "| Programming  ‚Üí [1]     | Guido van Rossum  ‚Üí [1] | 2022 ‚Üí [1]   |\n",
    "|              | Geoff Hinton      ‚Üí [2] |            |\n",
    "+--------------+---------------------+------------+\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "Example Search:\n",
    "\n",
    "Query: \"learning\" with filters {\"category\": \"AI\", \"year\": 2023}\n",
    "\n",
    "1. Text search may match Docs 0, 1, 2 based on TF-IDF.\n",
    "2. Apply keyword filters:\n",
    "    - category = \"AI\" ‚Üí keep Docs [0,2]\n",
    "    - year = 2023      ‚Üí keep Docs [0,2]\n",
    "3. Result after filtering ‚Üí [Doc 0, Doc 2]\n",
    "4. Rank using TF-IDF across text fields.\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "Summary:\n",
    "\n",
    "- Keyword fields map exact values ‚Üí document IDs.\n",
    "- Enable filtering, faceted search, and grouping.\n",
    "- Complement text fields, which are scored for relevance.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# can\n",
    "index = AppendableIndex(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)\n",
    "\n",
    "# to append , we can use the following function\n",
    "#index.append(XXXX);\n"
   ],
   "id": "a9b3482d6c55fbbb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x15054fe60>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T01:14:43.431835Z",
     "start_time": "2025-10-26T01:14:43.429327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the search function to get results from Search Index create above\n",
    "\"\"\"\n",
    "üß© TF-IDF + Boost Explanation in AppendableIndex\n",
    "\n",
    "TF-IDF = Term Frequency √ó Inverse Document Frequency\n",
    "It measures how important a word is in a document relative to the entire corpus.\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "1Ô∏è‚É£ Term Frequency (TF)\n",
    "- Counts how often a term appears in a document.\n",
    "- Sublinear scaling: TF = 1 + log(count), if count > 0\n",
    "- Example:\n",
    "    Doc 0, text: \"Deep learning learning learning\"\n",
    "    Count of \"learning\" = 3\n",
    "    TF(\"learning\") = 1 + log(3) ‚âà 2.10\n",
    "\n",
    "2Ô∏è‚É£ Inverse Document Frequency (IDF)\n",
    "- Measures how rare a term is across all documents.\n",
    "- Formula: IDF = log((N + 1) / (DF + 1)) + 1\n",
    "    - N = total number of documents\n",
    "    - DF = number of documents containing the term\n",
    "- Rare terms get higher IDF.\n",
    "\n",
    "Example:\n",
    "    3 documents contain \"learning\" in text field:\n",
    "        N = 3, DF(\"learning\") = 2\n",
    "        IDF(\"learning\") = log((3+1)/(2+1)) + 1 ‚âà 1.29\n",
    "\n",
    "3Ô∏è‚É£ TF-IDF\n",
    "- Multiply TF √ó IDF for each token in a document.\n",
    "- L2 normalize vectors to compare similarity with cosine similarity.\n",
    "\n",
    "Example Calculation for Doc 0:\n",
    "    - Token \"learning\": TF = 2.10, IDF = 1.29\n",
    "    - TF-IDF(\"learning\") = 2.10 * 1.29 ‚âà 2.71\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "4Ô∏è‚É£ Field Boosts\n",
    "\n",
    "- `boost_dict` in search allows weighting specific text fields.\n",
    "- Each field score is multiplied by its boost before combining.\n",
    "\n",
    "Example:\n",
    "\n",
    "Text fields: [\"question\", \"text\", \"section\"]\n",
    "Boosts: {\"question\": 2.0, \"text\": 1.0}  # section uses default 1.0\n",
    "\n",
    "Doc 0 raw TF-IDF scores for a query:\n",
    "+-----------+-----------+----------------+\n",
    "| Field     | Raw Score | Boosted Score  |\n",
    "+-----------+-----------+----------------+\n",
    "| question  | 0.5       | 0.5 * 2.0 = 1.0|\n",
    "| text      | 0.3       | 0.3 * 1.0 = 0.3|\n",
    "| section   | 0.2       | 0.2 * 1.0 = 0.2|\n",
    "+-----------+-----------+----------------+\n",
    "\n",
    "Total Score = 1.0 + 0.3 + 0.2 = 1.5\n",
    "- Boosting \"question\" doubles its impact on ranking.\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "5Ô∏è‚É£ How Search Works with TF-IDF + Boost\n",
    "\n",
    "1. Tokenize query and documents.\n",
    "2. Compute TF-IDF vectors for query and each document (per text field).\n",
    "3. Apply L2 normalization.\n",
    "4. Calculate cosine similarity between query vector and document vectors.\n",
    "5. Multiply each field score by its boost (from `boost_dict`).\n",
    "6. Combine scores across fields for final ranking.\n",
    "7. Optionally, apply keyword filters to remove non-matching documents.\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "Summary:\n",
    "\n",
    "- TF-IDF ranks documents based on query relevance.\n",
    "- Rare and query-specific terms get higher scores.\n",
    "- Field boosts allow tuning importance of specific fields.\n",
    "- Keyword fields filter results without affecting TF-IDF scoring.\n",
    "\"\"\"\n",
    "\n",
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'}, #This is used because we added it as a keyword field above\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "    )\n",
    "\n",
    "    return results"
   ],
   "id": "8731ab3b114caae5",
   "outputs": [],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T01:14:43.437483Z",
     "start_time": "2025-10-26T01:14:43.435903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the search tool\n",
    "# This is needed because when the LLM is deciding to pick a \"tool\" it use the description and the properties to call the tool.\n",
    "search_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"search\",\n",
    "    \"description\": \"Search the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": { #parameters\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query text to look up in the course FAQ.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n"
   ],
   "id": "616fd58c3754c541",
   "outputs": [],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T01:14:43.440809Z",
     "start_time": "2025-10-26T01:14:43.439457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set System prompt\n",
    "instructions = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\"\"\".strip()"
   ],
   "id": "810bdd42b46b59ff",
   "outputs": [],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T01:14:43.444395Z",
     "start_time": "2025-10-26T01:14:43.443055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the tools. in our case we are including search tool. More tools can be provided\n",
    "tools = [search_tool]"
   ],
   "id": "f53118ff5f917baf",
   "outputs": [],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T01:14:43.450047Z",
     "start_time": "2025-10-26T01:14:43.446386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "def print_response_readable(response):\n",
    "    \"\"\"\n",
    "    Pretty-print key parts of an OpenAI Response object in Jupyter.\n",
    "    Includes tool calls, function arguments, and model text outputs.\n",
    "    \"\"\"\n",
    "    print(\"üìù Response Summary\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Response ID: {getattr(response, 'id', None)}\")\n",
    "    print(f\"Model: {getattr(response, 'model', None)}\")\n",
    "    print(f\"Status: {getattr(response, 'status', None)}\")\n",
    "    print(f\"Tool Choice: {getattr(response, 'tool_choice', None)}\")\n",
    "    print(f\"Parallel Tool Calls: {getattr(response, 'parallel_tool_calls', None)}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Print tool outputs\n",
    "    if hasattr(response, 'output') and response.output:\n",
    "        for i, item in enumerate(response.output):\n",
    "            item_type = getattr(item, 'type', None)\n",
    "\n",
    "            if item_type == 'function_call':\n",
    "                print(f\"üîß Tool Call [{i}]: {getattr(item, 'name', None)}\")\n",
    "                print(f\"    Call ID: {getattr(item, 'call_id', None)}\")\n",
    "                print(f\"    Status: {getattr(item, 'status', None)}\")\n",
    "                # Arguments as pretty JSON\n",
    "                args = getattr(item, 'arguments', None)\n",
    "                if args:\n",
    "                    try:\n",
    "                        args_json = json.loads(args)\n",
    "                        print(\"    Arguments:\")\n",
    "                        pprint(args_json, indent=4)\n",
    "                    except Exception:\n",
    "                        print(f\"    Arguments: {args}\")\n",
    "\n",
    "            elif item_type == 'text':\n",
    "                text_content = getattr(item, 'content', None)\n",
    "                print(f\"üí¨ Model Text Output [{i}]:\")\n",
    "                if text_content:\n",
    "                    if isinstance(text_content, list):\n",
    "                        # Sometimes output content is a list of dicts with 'text'\n",
    "                        for part in text_content:\n",
    "                            pprint(part.get('text', ''), indent=4)\n",
    "                    else:\n",
    "                        pprint(text_content, indent=4)\n",
    "                else:\n",
    "                    print(\"    <No text content>\")\n",
    "            else:\n",
    "                # Fallback for unknown output types\n",
    "                print(f\"[{i}] Output item (type: {item_type}):\")\n",
    "                pprint(item)\n",
    "    else:\n",
    "        print(\"No outputs found.\")\n",
    "\n",
    "    print(\"-\" * 60)\n"
   ],
   "id": "f4f43171f7f29883",
   "outputs": [],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T01:14:44.325494Z",
     "start_time": "2025-10-26T01:14:43.452429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Create Open AI Client\n",
    "from openai import OpenAI\n",
    "openai_client = OpenAI()\n",
    "\n",
    "question = 'I just discovered the course. Can I still join it?'\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": instructions}, #intermediary\n",
    "    {\"role\": \"user\", \"content\": question} #from users\n",
    "]\n",
    "\n",
    "# Send the tools defines along with the system prompt and user question\n",
    "response = openai_client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")\n"
   ],
   "id": "8b90b98f5284786c",
   "outputs": [],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T01:14:44.356112Z",
     "start_time": "2025-10-26T01:14:44.351724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "#Checkout the response. This will have instructions asking to call the search tool to get the data.\n",
    "print_response_readable(response)"
   ],
   "id": "27541050c9443f3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Response Summary\n",
      "------------------------------------------------------------\n",
      "Response ID: resp_063994e02160e3740068fd760392fc819495f10f9b784e1582\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Status: completed\n",
      "Tool Choice: auto\n",
      "Parallel Tool Calls: True\n",
      "------------------------------------------------------------\n",
      "üîß Tool Call [0]: search\n",
      "    Call ID: call_LtdrG9M2jCpft5vKf8VvuxEr\n",
      "    Status: completed\n",
      "    Arguments:\n",
      "{'query': 'join course'}\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T01:14:44.368893Z",
     "start_time": "2025-10-26T01:14:44.364114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# write a function that takes in the call object and returns back a json formatted value\n",
    "# that can be passed onto the Open AI call with chat messages\n",
    "\n",
    "def call_search_tool(call):\n",
    "    arguments = json.loads(call.arguments)\n",
    "    query = arguments['query']\n",
    "    search_results = json.dumps(search(query))\n",
    "    return {\n",
    "        \"type\": \"function_call_output\",\n",
    "        \"call_id\": call.call_id,\n",
    "        \"output\": json.dumps(search_results)\n",
    "    }"
   ],
   "id": "d2af34c7d1228218",
   "outputs": [],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T01:14:44.376247Z",
     "start_time": "2025-10-26T01:14:44.374371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "# let's put the response in an object called callParameters\n",
    "# The key here is\n",
    "## name : This is the name of the tool\n",
    "## type : How we expect the tool to work. In our case it's a function_call\n",
    "## id : An id that will be used by OpenAI to match the response of the function call\n",
    "## arguments : The arguments that should be provided to the tool\n",
    "\n",
    "call = response.output[0]\n",
    "chat_messages.append(call)"
   ],
   "id": "7e9a1c8bec3073f9",
   "outputs": [],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T01:14:44.389191Z",
     "start_time": "2025-10-26T01:14:44.381530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# append the result to chat messages and send it back to OpenAI\n",
    "search_tool_response = call_search_tool(call)\n",
    "chat_messages.append(search_tool_response)\n",
    "print(len(chat_messages))"
   ],
   "id": "84852eb83dad53a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "execution_count": 143
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T01:14:46.408525Z",
     "start_time": "2025-10-26T01:14:44.392899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Send the tools defines along with the system prompt and user question and tool output\n",
    "\n",
    "response_with_tool_output = openai_client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")"
   ],
   "id": "3597d010ef082fe0",
   "outputs": [],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T01:14:46.429746Z",
     "start_time": "2025-10-26T01:14:46.427728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print_response_readable(response_with_tool_output)\n",
    "#print(response_with_tool_output)"
   ],
   "id": "866b6dfca052a4c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Response Summary\n",
      "------------------------------------------------------------\n",
      "Response ID: resp_063994e02160e3740068fd760479b48194b4ab7ab3b28e752e\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Status: completed\n",
      "Tool Choice: auto\n",
      "Parallel Tool Calls: True\n",
      "------------------------------------------------------------\n",
      "[0] Output item (type: message):\n",
      "ResponseOutputMessage(id='msg_063994e02160e3740068fd760544288194a90cc27a428d33cf', content=[ResponseOutputText(annotations=[], text='Yes, you can still join the course even after its start date. You are eligible to submit homework assignments, but keep in mind that there are deadlines for turning in the final projects, so it‚Äôs best not to leave everything to the last minute.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T01:14:46.442041Z",
     "start_time": "2025-10-26T01:14:46.439387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "üß© OpenAI Function/Tool Calling Flow (ASCII Diagram)\n",
    "https://platform.openai.com/docs/guides/function-calling#the-tool-calling-flow\n",
    "\n",
    "User Input\n",
    "   ‚îÇ\n",
    "   ‚ñº\n",
    "+-----------------+\n",
    "| System Message  |\n",
    "| (instructions)  |\n",
    "+-----------------+\n",
    "   ‚îÇ\n",
    "   ‚ñº\n",
    "+-----------------+\n",
    "| Model Receives  |\n",
    "| User Prompt     |\n",
    "+-----------------+\n",
    "   ‚îÇ\n",
    "   ‚ñº\n",
    "+-----------------+\n",
    "| Model Decides   |\n",
    "| Whether to Call |\n",
    "| a Tool/Function |\n",
    "+-----------------+\n",
    "   ‚îÇ\n",
    "   ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Function Call ‚îÇ\n",
    "‚îÇ (name + args) ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "   ‚îÇ\n",
    "   ‚ñº\n",
    "+-----------------+\n",
    "| Function Executes|\n",
    "| with Provided   |\n",
    "| Arguments       |\n",
    "+-----------------+\n",
    "   ‚îÇ\n",
    "   ‚ñº\n",
    "+-----------------+\n",
    "| Function Output |\n",
    "| returned to     |\n",
    "| Model           |\n",
    "+-----------------+\n",
    "   ‚îÇ\n",
    "   ‚ñº\n",
    "+-----------------+\n",
    "| Model Generates |\n",
    "| Final Response  |\n",
    "| for User        |\n",
    "+-----------------+\n",
    "\n",
    "Notes:\n",
    "- Tools/functions are defined with names, descriptions, and parameters.\n",
    "- Model may call multiple tools in parallel if enabled.\n",
    "- Tool outputs can be used by the model to generate more accurate final responses.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "If this goes in a loop where the LLM asks us to call tools and we send the responses and the LLM asks us to call the tools again till we find the answer. It's an LLM with Loops i.e. it is showing \"Agency\" in deciding which tools to use, take the output and make more decisions to see if other tools are called before providing an answer. This interaction is called an Agentic Loop which is the heart of an Agent\n",
    "\"\"\""
   ],
   "id": "9416ac77975d28f4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIf this goes in a loop where the LLM asks us to call tools and we send the responses and the LLM asks us to call the tools again till we find the answer. It\\'s an LLM with Loops i.e. it is showing \"Agency\" in deciding which tools to use, take the output and make more decisions to see if other tools are called before providing an answer. This interaction is called an Agentic Loop which is the heart of an Agent\\n'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T01:14:46.450820Z",
     "start_time": "2025-10-26T01:14:46.448726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "We will first write a function to automate the tool calling.\n",
    "Remember that the LLM has already provided you the tool name it wants to be called and the arguments\n",
    "All you need to do is use them to call the right function\n",
    "\"\"\"\n",
    "def make_call(call_request_from_llm):\n",
    "    f_name = call_request_from_llm.name # Coming from LLM\n",
    "    arguments = json.loads(call_request_from_llm.arguments) # Coming from LLM\n",
    "\n",
    "    if f_name == 'search':\n",
    "        results = search(**arguments)\n",
    "    # if you add another function, we can put it here\n",
    "    # elif f_name == 'add_entry':\n",
    "    #    results = add_entry(**arguments)\n",
    "    else:\n",
    "        raise ValueError(f'unknown function {f_name}')\n",
    "\n",
    "    json_results = json.dumps(results)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"function_call_output\",\n",
    "        \"call_id\": call_request_from_llm.call_id, # This is for the llm to know which tool request this response is for.\n",
    "        \"output\": json_results,\n",
    "    }\n",
    "\n"
   ],
   "id": "9ceb5fa4a157c13e",
   "outputs": [],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T01:14:50.167986Z",
     "start_time": "2025-10-26T01:14:46.458160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question = 'I just discovered the course. Can I still join it?'\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": instructions},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "while True: #agent loop\n",
    "    response = openai_client.responses.create(\n",
    "        model='gpt-4o-mini',\n",
    "        input=chat_messages,\n",
    "        tools=tools\n",
    "    )\n",
    "\n",
    "    has_function_calls = False\n",
    "\n",
    "    # Add response to chat history for LLM's \"memory\"\n",
    "    chat_messages.extend(response.output) #we keep adding all the tool call requests along with it's responses.\n",
    "\n",
    "    for entry in response.output:\n",
    "        if entry.type == \"function_call\":\n",
    "            print('Function call:')\n",
    "            print(entry)\n",
    "            result = make_call(entry)\n",
    "            print('   ', 'Output:')\n",
    "            print('   ', result['output'])\n",
    "            chat_messages.append(result) # We add the result and we also add the call_id. see the make_call function.\n",
    "            has_function_calls = True\n",
    "            print()\n",
    "\n",
    "        elif entry.type == \"message\":\n",
    "            print('Assistant:')\n",
    "            print(entry.content[0].text)\n",
    "            print()\n",
    "\n",
    "    if not has_function_calls:\n",
    "        break"
   ],
   "id": "3101fd0719c75b5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function call:\n",
      "ResponseFunctionToolCall(arguments='{\"query\":\"join course late enrollment\"}', call_id='call_Bvw4LnXuwpsB02L2ODj7aFGC', name='search', type='function_call', id='fc_017fd55038a01de30068fd7607d3908195b5289763b647c512', status='completed')\n",
      "    Output:\n",
      "    [{\"text\": \"No, late submissions are not allowed. But if the form is still not closed and it\\u2019s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\\nOlder news:[source1] [source2]\", \"section\": \"General course-related questions\", \"question\": \"Homework - Are late submissions of homework allowed?\", \"course\": \"data-engineering-zoomcamp\"}, {\"text\": \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\", \"section\": \"General course-related questions\", \"question\": \"Course - Can I still join the course after the start date?\", \"course\": \"data-engineering-zoomcamp\"}, {\"text\": \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  \\u201cOffice Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon\\u2019t forget to register in DataTalks.Club's Slack and join the channel.\", \"section\": \"General course-related questions\", \"question\": \"Course - When will the course start?\", \"course\": \"data-engineering-zoomcamp\"}, {\"text\": \"After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\\nHaving this local repository on your computer will make it easy for you to access the instructors\\u2019 code and make pull requests (if you want to add your own notes or make changes to the course content).\\nYou will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\\nRemember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\\nThis is also a great resource: https://dangitgit.com/\", \"section\": \"General course-related questions\", \"question\": \"How do I use Git / GitHub for this course?\", \"course\": \"data-engineering-zoomcamp\"}, {\"text\": \"No, you can only get a certificate if you finish the course with a \\u201clive\\u201d cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\", \"section\": \"General course-related questions\", \"question\": \"Certificate - Can I follow the course in a self-paced mode and get a certificate?\", \"course\": \"data-engineering-zoomcamp\"}]\n",
      "\n",
      "Assistant:\n",
      "Yes, you can still join the course even if you've discovered it after the start date. However, keep in mind that there will be deadlines for submitting the final projects, so it's best not to leave everything until the last minute. Make sure to register as soon as possible to keep up with the course materials!\n",
      "\n"
     ]
    }
   ],
   "execution_count": 148
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
